# Mathematics of Machine Learning Summer School (Alan Turing Institute)

![Alan Turing Institute Logo](https://www.turing.ac.uk/sites/default/files/styles/media_crop/public/media/ATI_Logo_0.png)

## Overview

This repository contains comprehensive resources from the **Mathematics of Machine Learning Summer School 2021**, organized by the Alan Turing Institute. The course provides a rigorous theoretical framework for machine learning, with a particular emphasis on **supervised learning**. It combines theoretical foundations with practical numerical experiments using **Python (TensorFlow)** in Jupyter notebooks and Colab.

The main goal of this course is to equip learners with the mathematical tools and computational skills needed to understand and implement state-of-the-art machine learning techniques.

**Course website:** [Alan Turing Institute - Mathematics of ML Summer School](https://www.turing.ac.uk/courses/mathematics-machine-learning-summer-school)  

---

## Learning Outcomes

By the end of this course, learners will be able to:

- Explain the basic formulation of machine learning as a **stochastic minimization problem** and understand what it means to solve the problem optimally.  
- Use **non-asymptotic methods** to study random structures in high-dimensional probability, statistics, and optimization.  
- Run numerical experiments using **Python (TensorFlow)** on Jupyter notebooks via Colab.  

---

## Course Structure

The course is organized into **five modules**, each covering key topics in machine learning theory and practical methods.

### Module 1

**Topics:**
- Lecture 1: Introduction  
- Lecture 2: Concentration Inequalities; Bounds in Probability  

### Module 2

**Topics:**
- Lecture 3: Bernstein’s Concentration Inequalities; Fast Rates  
- Lecture 4: Maximal Inequalities and Rademacher Complexity  

### Module 3

**Topics:**
- Lecture 5: Convex Loss Surrogates; Gradient Descent  
- Lecture 6: Mirror Descent  

### Module 4

**Topics:**
- Lecture 7: Stochastic Methods; Algorithmic Stability  
- Lecture 8: Least Squares; Implicit Bias and Regularization  

### Module 5

**Topics:**
- Lecture 9: High-Dimensional Statistics; Gaussian Complexity  
- Lecture 10: The Lasso Estimator; Proximal Gradient Methods  

---

## Labs & Projects

This repository also includes all **project and lab exercises** provided during the summer school. These exercises are designed to reinforce the theoretical concepts covered in the lectures through hands-on experimentation.

---

## Instructors

- **Professor Patrick Rebeschini** – Alan Turing Institute  
- **Tomas Vaškevičius** – University of Oxford, Department of Statistics  

---

## Resources

- [Lecture Slides & Notes](https://github.com/alan-turing-institute/mathematics-of-ml-course)  
- [Jupyter Notebooks on Colab](https://github.com/alan-turing-institute/mathematics-of-ml-course)  
- [Course Website](https://www.turing.ac.uk/courses/mathematics-machine-learning-summer-school)  

---

## License

This repository is for educational purposes. Please refer to the original course and resources for licensing information.

---

*Compiled and organized by [Your Name/Username] to provide a comprehensive reference for learners and practitioners in machine learning.*
